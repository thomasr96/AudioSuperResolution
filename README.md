# AudioSuperResultion

This repository holds code to train, test, and run audio super resolution deep learning models. I trained autoencoder and GAN style models, first taking ideas from literature and then by building on top of them. The main part of the project was for speech audio, where the VCTK Speech Dataset was used. The FMA music dataset was then also used for separate training, although their performance did not compare even close to the VCTK based models for their respective task.

Please view `Read Me.ipynb` for a programmatic tour of the project and `deep_learning_project.pdf` for the academic report. If you wish to run the WGAN models, then checkout 
my Google Drive for the WGAN (Wasserstein-GAN) models for upsampling ratios of [r=2]() and  [$r=4$](https://drive.google.com/file/d/1ocOclR5h06aJaluPgpdCOzKWE8CSMvI4/view?usp=sharing).
